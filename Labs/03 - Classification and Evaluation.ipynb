{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Support Vector Machine (SVM) Classification and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we initially re-examine the spam filtering problem from Lab 2. This time, we train a Logistic Regression model and a linear Support Vector Machine for the spam or non-spam classification task. In the second part of the lab we examine classification evaluation by using a K-nearest neighbour classifier.\n",
    "\n",
    "\n",
    "All the datasets that you will need for this lab are located within the `datasets` directory (adjacent to this file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from pandas.api.types import CategoricalDtype\n",
    "KNeighboursClassifier = KNeighborsClassifier # For the Brits!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Load `spambase_binary.csv` into a pandas DataFrame structure called `spambase`. Display the number of instances and attributes and the first 5 samples. Remember that the attributes have been binarised. The instances have also been shuffled (i.e. their order has been randomised). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 4601, number of attributes = 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make_binarized</th>\n",
       "      <th>word_freq_address_binarized</th>\n",
       "      <th>word_freq_all_binarized</th>\n",
       "      <th>word_freq_3d_binarized</th>\n",
       "      <th>word_freq_our_binarized</th>\n",
       "      <th>word_freq_over_binarized</th>\n",
       "      <th>word_freq_remove_binarized</th>\n",
       "      <th>word_freq_internet_binarized</th>\n",
       "      <th>word_freq_order_binarized</th>\n",
       "      <th>word_freq_mail_binarized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu_binarized</th>\n",
       "      <th>word_freq_table_binarized</th>\n",
       "      <th>word_freq_conference_binarized</th>\n",
       "      <th>char_freq_;_binarized</th>\n",
       "      <th>char_freq_(_binarized</th>\n",
       "      <th>char_freq_[_binarized</th>\n",
       "      <th>char_freq_!_binarized</th>\n",
       "      <th>char_freq_$_binarized</th>\n",
       "      <th>char_freq_#_binarized</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make_binarized  word_freq_address_binarized  \\\n",
       "0                         0                            1   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   word_freq_all_binarized  word_freq_3d_binarized  word_freq_our_binarized  \\\n",
       "0                        0                       0                        1   \n",
       "1                        0                       0                        0   \n",
       "2                        1                       0                        0   \n",
       "3                        1                       0                        1   \n",
       "4                        0                       0                        1   \n",
       "\n",
       "   word_freq_over_binarized  word_freq_remove_binarized  \\\n",
       "0                         0                           1   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   word_freq_internet_binarized  word_freq_order_binarized  \\\n",
       "0                             1                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          1   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   word_freq_mail_binarized   ...     word_freq_edu_binarized  \\\n",
       "0                         1   ...                           0   \n",
       "1                         0   ...                           1   \n",
       "2                         0   ...                           0   \n",
       "3                         0   ...                           0   \n",
       "4                         0   ...                           0   \n",
       "\n",
       "   word_freq_table_binarized  word_freq_conference_binarized  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   char_freq_;_binarized  char_freq_(_binarized  char_freq_[_binarized  \\\n",
       "0                      0                      1                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   char_freq_!_binarized  char_freq_$_binarized  char_freq_#_binarized  \\\n",
       "0                      1                      1                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      1                      0                      0   \n",
       "4                      1                      1                      0   \n",
       "\n",
       "   is_spam  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'datasets', 'spambase_binary.csv')\n",
    "spambase_bin = pd.read_csv(data_path, delimiter = ',')\n",
    "print('Number of instances = {}, number of attributes = {}'.format(len(spambase_bin), len(spambase_bin.columns)))\n",
    "spambase_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "We are going to use hold-out validation to evaluate our models below. Split the dataset into training and testing subsets using the `train_test_split` [function](http://scikit-learn.org/0.19/modules/generated/sklearn.cross_validation.train_test_split.html) we have used before. Call the resulting matrices `X_train`, `X_test`, `y_train`, `y_test`. Use 90% of the data for training and the remaining 10% for testing. Make sure you don't include the target variable `is_spam` in the input features (`X_train` / `X_test`)!\n",
    "\n",
    "If you want to be able to reproduce your results exactly, what argument must you remember to set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spambase_bin.drop('is_spam', axis=1)\n",
    "y = spambase_bin['is_spam']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *To make results reproducable, set random_state*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "Train a [`LogisticRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier by using training data. Use the `lbfgs` solver and default settings for the other parameters. Report the classification accuracy on both the training and test sets. Does your classifier generalise well on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.9350241545893719, testing accuracy = 0.928416485900217\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "train_acc = logreg.score(X_train, y_train)\n",
    "test_acc = logreg.score(X_test, y_test)\n",
    "print('Training accuracy = {}, testing accuracy = {}'.format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *Yes, the classifier does almost as well on unseen data as on training data (<0.1 difference).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "Print the coefficients for class 1 for the attributes `word_freq_hp_binarized` and `char_freq_$_binarized`. Generally, we would expect the string `$` to appear in spam, and the string `hp` to appear in non-spam e-mails, as the data was collected from HP Labs. Do the regression coefficients make sense given that class 1 is spam? *Hint: Consider the sigmoid function and how it transforms values into a probability between 0 and 1. Since our attributes are boolean, a positive coefficient can only increase the total sum fed through the sigmoid and thus move the output of the sigmoid towards 1. What can happen if we have continuous, real-valued attributes?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp coef = -2.639347200187426, $ coef = 1.6986427332527392\n"
     ]
    }
   ],
   "source": [
    "index1 = np.where(X_train.columns == 'word_freq_hp_binarized')\n",
    "index2 = np.where(X_train.columns == 'char_freq_$_binarized')\n",
    "coef = logreg.coef_[0]\n",
    "print('hp coef = {}, $ coef = {}'.format(coef[index1][0], coef[index2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *We would expect hp to have a negative coefficient and $ to have a positive coefficient, assuming the former is not found in spam while this latter is. This is exactly the result we get. With continuous, real-valued attributes, if they are negative, a positive coeficient no longer shifts the sigmoid towards 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "Train a [`LinearSVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (i.e. Linear Support Vector classifier) by using default parameters. Report the classification accuracy on the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.9345410628019324, testing accuracy = 0.9197396963123644\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "train_acc = svc.score(X_train, y_train)\n",
    "test_acc = svc.score(X_test, y_test)\n",
    "print('Training accuracy = {}, testing accuracy = {}'.format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "What are the coefficients for the attributes `word_freq_hp_binarized` and `char_freq_`$`_binarized`? Compare these to the ones you found with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp coef = -0.8567712455753931, $ coef = 0.5693545276432318\n"
     ]
    }
   ],
   "source": [
    "coef = svc.coef_[0]\n",
    "print('hp coef = {}, $ coef = {}'.format(coef[index1][0], coef[index2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *The hp coefficient is once again negative, while the $ coefficient is once again positive, however their magnitude is less*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "How does a linear SVM relate to Logistic Regression? *Hint: Consider the classification boundary learnt in each model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *They both form a linear decision boundary to divide classes. Their way of forming this boundary is extremely different, however.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "By using the [`SVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) class train two new support vector classifiers with Gaussian (`rbf`) and polynomial (`poly`) kernels. Again, report classification accuracies on training and test sets and compare with your results from Question 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVC training accuracy = 0.9342995169082126, testing accuracy = 0.93058568329718\n",
      "Polynomial SVC training accuracy = 0.8002415458937198, testing accuracy = 0.8091106290672451\n"
     ]
    }
   ],
   "source": [
    "svc_rbf = SVC(kernel='rbf')\n",
    "svc_rbf.fit(X_train, y_train)\n",
    "train_acc = svc_rbf.score(X_train, y_train)\n",
    "test_acc = svc_rbf.score(X_test, y_test)\n",
    "print('Gaussian SVC training accuracy = {}, testing accuracy = {}'.format(train_acc, test_acc))\n",
    "\n",
    "svc_poly = SVC(kernel='poly')\n",
    "svc_poly.fit(X_train, y_train)\n",
    "train_acc = svc_poly.score(X_train, y_train)\n",
    "test_acc = svc_poly.score(X_test, y_test)\n",
    "print('Polynomial SVC training accuracy = {}, testing accuracy = {}'.format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *The Gaussian SVC performed almost exactly the same on the training set as the linear SVC from before, however generalised better to unseen data. The Polyonmial SVC gave worse accuracy for both the training and test sets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance assessment\n",
    "We will now look at a few ways of assessing the performance of a classifier. To do so we will introduce a new data set, the [Splice](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) data set. The classification task is to identify `intron` and `exon` boundaries on gene sequences. For more information, you can read the dataset description in the link. The class attribute can take on 3 values: `N`, `IE` and `EI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "Load the `splice_train.csv` and `splice_test.csv` into two separate dataframes. Display the shape and first 10 instances for each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    T    G    A    T    G    C    C    T    G    C  ...      C     C     C   \n",
       "1    G    C    C    C    A    T    A    T    T    C  ...      T     G     G   \n",
       "2    G    G    C    T    G    C    C    G    G    A  ...      A     C     T   \n",
       "3    C    T    G    C    T    G    C    T    G    G  ...      G     G     C   \n",
       "4    T    C    C    C    C    G    A    G    C    C  ...      A     T     C   \n",
       "5    A    T    A    C    C    T    G    C    C    C  ...      A     T     G   \n",
       "6    T    T    C    T    C    C    A    T    T    T  ...      G     A     T   \n",
       "7    A    A    A    G    A    T    G    A    T    A  ...      A     A     G   \n",
       "8    C    C    A    A    T    C    C    C    A    G  ...      G     G     C   \n",
       "9    G    C    C    G    T    G    G    T    T    T  ...      A     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     C     C     T     G     A     G     N  \n",
       "1     A     C     T     T     C     C     N  \n",
       "2     G     T     G     T     C     T    EI  \n",
       "3     T     G     C     T     G     G    EI  \n",
       "4     A     G     C     G     C     A     N  \n",
       "5     G     G     G     T     C     T    EI  \n",
       "6     A     T     C     C     A     T    IE  \n",
       "7     C     C     C     T     T     C    EI  \n",
       "8     G     G     C     C     T     G     N  \n",
       "9     G     C     T     C     C     T    EI  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Splice Train Here\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'splice_train.csv')\n",
    "splice_train = pd.read_csv(data_path, delimiter = ',')\n",
    "splice_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    C    C    C    T    C    C    C    A    C    T  ...      C     C     C   \n",
       "1    C    A    C    T    G    A    G    T    T    G  ...      G     A     A   \n",
       "2    C    A    G    A    C    T    G    G    G    T  ...      A     G     A   \n",
       "3    A    G    T    G    A    T    T    G    A    C  ...      T     A     C   \n",
       "4    G    T    A    G    A    C    A    C    C    T  ...      A     T     C   \n",
       "5    C    T    T    G    T    T    A    C    A    G  ...      C     C     G   \n",
       "6    C    G    T    C    A    A    T    C    A    A  ...      A     A     A   \n",
       "7    G    T    C    C    G    T    G    C    C    T  ...      G     C     C   \n",
       "8    A    T    A    C    C    T    G    T    A    G  ...      C     G     T   \n",
       "9    G    G    T    G    G    G    C    C    A    A  ...      C     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     A     G     T     G     C     A    IE  \n",
       "1     C     C     A     G     T     G     N  \n",
       "2     C     C     A     C     A     G    EI  \n",
       "3     C     A     A     A     G     A     N  \n",
       "4     C     C     T     T     C     T    IE  \n",
       "5     A     G     A     A     C     C     N  \n",
       "6     A     T     T     A     A     G    EI  \n",
       "7     C     T     T     T     G     C     N  \n",
       "8     T     T     A     T     A     T     N  \n",
       "9     G     C     A     T     G     G     N  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Splice Test Here\n",
    "data_path = os.path.join(os.getcwd(), 'datasets', 'splice_test.csv')\n",
    "splice_test = pd.read_csv(data_path, delimiter = ',')\n",
    "splice_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ========== \n",
    "Convert the categorical attributes into numeric ones by using the [`get_dummies(...)`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.get_dummies.html) function from pandas. Make sure to take care of the values `D`, `N`, `S`, `R` (see the [documentation](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) for the data). *Hint: checkout the pandas [`CategoricalDtype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.api.types.CategoricalDtype.html#pandas.api.types.CategoricalDtype)*. Also, make sure to not transform the target variable (`class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype = CategoricalDtype(['A', 'G', 'T', 'C', 'D', 'N', 'R', 'S'])\n",
    "splice_train_onehot = pd.get_dummies(splice_train.drop('class', axis=1).astype(ctype))\n",
    "splice_test_onehot = pd.get_dummies(splice_test.drop('class', axis=1).astype(ctype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Store the training and testing data into numpy arrays `X_train`, `y_train`, `X_test` and `y_test`. Display the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (2935, 480)\n",
      "y_train shape = (2935,)\n",
      "X_train shape = (255, 480)\n",
      "y_test shape = (255,)\n"
     ]
    }
   ],
   "source": [
    "X_train = splice_train_onehot.values\n",
    "X_test = splice_test_onehot.values\n",
    "y_train = splice_train[\"class\"]\n",
    "y_test = splice_test[\"class\"]\n",
    "print('X_train shape = {}'.format(X_train.shape))\n",
    "print('y_train shape = {}'.format(y_train.shape))\n",
    "print('X_train shape = {}'.format(X_test.shape))\n",
    "print('y_test shape = {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ==========\n",
    "Familiarise yourself with [Nearest Neighbours Classification](http://scikit-learn.org/0.19/modules/neighbors.html#classification). Use a [`KNeighborsClassifier`](http://scikit-learn.org/0.19/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "by using a single neighbour. Report the classification accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "round(knn.score(X_train, y_train), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 ==========\n",
    "Is the above result meaningful? Why is testing on the training data a particularly bad idea for a 1-nearest neighbour classifier? Do you expect the performance of the classifier on a test set to be as good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *This is not meaningful as each point will be its own nearest neighbour, thus 100% accuracy will be acheived. This could be different with more that one nearest neighbour, as it would no longer correctly classify outliers. The test set performance will certainly be worse.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "Now report the classification accuracy on the test set and check your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450980392156863"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Plot a histogram of the target variable (i.e. `class`) in the test set. *Hint: matplotlib won't allow you to plot a histogram for categorical values. Instead, you can use Pandas' built-in bar plot tool in conjunction with the [`value_counts`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.value_counts.html).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "What would be the accuracy of the classifier, if all points were labelled as `N`? \n",
    "\n",
    "**Pro Tip** - You should always use a ['Dummy Model'](http://scikit-learn.org/0.19/modules/model_evaluation.html#dummy-estimators) (a ridiculously simple model) like this to compare with your 'real' models. It's very common for complex models to be outperformed by a simple model, such as predicting the most common class. When complex models are outperformed by 'Dummies', you should investigate why: often there was an issue with the code, the data, or the way the model works was misunderstood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5843137254901961"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyn = DummyClassifier(strategy='most_frequent')\n",
    "dummyn.fit(X_train, y_train)\n",
    "dummyn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "Now we want to explore the effect of the `k` parameter. To do this, train the classifier multiple times, each time setting the KNN option to a different value. Try `5`, `10`, `50`, `100`, `200`, `500`, `1000`, `1500` and `2000` and test the classifier on the test set. How does the k parameter effect the results? *Hint: Consider how well the classifier is generalising to previously unseen data, and how it compares to the dumb prediction accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "# NEIGHBOURS   ACCURACY     \n",
      "-----------------------\n",
      "5              0.773        \n",
      "10             0.812        \n",
      "50             0.867        \n",
      "100            0.886        \n",
      "200            0.906        \n",
      "500            0.949        \n",
      "1000           0.965        \n",
      "1500           0.698        \n",
      "2000           0.584        \n"
     ]
    }
   ],
   "source": [
    "print('-' * 23)\n",
    "print('{:<15s}{:<13s}'.format('# NEIGHBOURS','ACCURACY'))\n",
    "print('-' * 23)\n",
    "\n",
    "accs = []\n",
    "ks = [5, 10, 50, 100, 200, 500, 1000, 1500, 2000]\n",
    "\n",
    "for i in ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc = round(knn.score(X_test, y_test), 3)\n",
    "    accs.append(acc)\n",
    "    print('{:<15s}{:<13s}'.format(str(i),str(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *The accuracy increases from slightly better than the dummy at 5nn, to 96.5% accuracy at 1000nn, before peformance decreases rapidly for 1500, reaching the same as that of the dummy classifier at 2000nn.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "Plot the results (k-value on the x-axis and classification accuracy on the y-axis), making sure to mark the axes. Can you conclude anything from observing the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(ks, accs)\n",
    "plt.xlabel('K-value')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *Evidently more neighbours generally means better accuracy, until too many neighbours are used which greatly reduces accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "Select best value for `k` from Questions 2.9 and 2.10 and plot the normalised confusion matrix on the test set (you may use the provided function). Then plot the confusion matrix for a 5-nearest neighbour classifier. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using K=1000 as the number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors=1000)\n",
    "knn.fit(X_train, y_train)\n",
    "test_pred = knn.predict(X_test)\n",
    "conf = confusion_matrix(y_test, test_pred)\n",
    "conf = conf/[[sum(conf[i])] for i in range(len(conf))]\n",
    "plot_confusion_matrix(conf, classes=np.unique(y_test), title='1000NN')\n",
    "plt.show()\n",
    "\n",
    "# Using K=5 as the number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "test_pred = knn.predict(X_test)\n",
    "conf = confusion_matrix(y_test, test_pred)\n",
    "conf = conf/[[sum(conf[i])] for i in range(len(conf))]\n",
    "plot_confusion_matrix(conf, classes=np.unique(y_test), title='5NN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *The classifier works much better with 1000NN than 5NN, most notably in the classifiation of 'N'.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "Read about the [logarithimic loss](http://scikit-learn.org/0.19/modules/generated/sklearn.metrics.log_loss.html) (or cross-entropy loss). It is often the error metric used when we are trying to optimise classification models.\n",
    "\n",
    "This metric takes as input the true labels and the estimated probability distributions (bernouli or multinomial). It makes sense to use this metric when we are interested not only in the predicted labels, but also in the confidence with which these labels are predicted.\n",
    "\n",
    "For instance, think of the situation where you have a single test point and two classifiers. Both classifiers predict the label correctly, however classifier A predicts that the test point belongs to the class with probability 0.55, whereas classifier B predicts the correct class with probability 0.99. Classification accuracy would be the same for the two classifiers (why?) but the `log_loss` metric would indicate that classifier B should be favoured.\n",
    "\n",
    "Produce a scatter plot similar to the one in Question 2.10 but this time show `log_loss` on your y axis. Which value for `k` would you pick if `log_loss` was the error metric? Comment on why this might happen, and which metric would be a better evaluator of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "# NEIGHBOURS   ACCURACY     \n",
      "-----------------------\n",
      "5              1.098749665258065\n",
      "10             0.48269823951654434\n",
      "50             0.5295699221124731\n",
      "100            0.5575541329984139\n",
      "200            0.6010940389068344\n",
      "500            0.670927600876827\n",
      "1000           0.754663389026571\n",
      "1500           0.8177287055931994\n",
      "2000           0.8753647883393483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('-' * 23)\n",
    "print('{:<15s}{:<13s}'.format('# NEIGHBOURS','ACCURACY'))\n",
    "print('-' * 23)\n",
    "\n",
    "lls = []\n",
    "ks = [5, 10, 50, 100, 200, 500, 1000, 1500, 2000]\n",
    "\n",
    "for i in ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    test_pred = knn.predict_proba(X_test)\n",
    "    ll = log_loss(y_true=y_test, y_pred=test_pred)\n",
    "    lls.append(ll)\n",
    "    print('{:<15s}{:<13s}'.format(str(i), str(ll)))\n",
    "\n",
    "sns.scatterplot(ks, lls)\n",
    "plt.xlabel('K-value')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *I would choose K=10 as this gives he lowest log-loss. The 10NN model, while it gets more instances wrong (lower accuracy), has a better judgement of its confidence in the prediction, whereas the 1000NN model gets more instances right (higher accuracy), but its judgement is way off (for example, in instances where it gets it wrong, it may predict the wrong label with high confidence, impacting the log loss).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 ==========\n",
    "\n",
    "Could you use the `log_loss` metric to evaluate the performance of an SVM classifier? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your answer goes here:*** *You shouldn't as SVM does not use probability to classify, it simply tries to minimise a distance metric.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
